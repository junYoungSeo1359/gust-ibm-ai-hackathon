{"cells":[{"cell_type":"markdown","metadata":{},"source":["## 노트북 내용\n","\n","이 노트북은 watsonx.ai를 사용한 RAG (Retrieval Augmented Generation)을 테스트 하기 위한 예제입니다. 여기에는 data retrieval, 지식 기본 정보에서 유사도검색 및 모델이 생성한 결과를 확인하는 내용이 포함되어 있습니다.\n","이를 잘 이해하기 위해서는 Python에 대한 기본 지식이 필요하며 모든 코드는 Python 3.12 으로 작성되어 있습니다.\n","\n","### RAG (Retrieval Augmented Generation) \n","Retrieval Augmented Generation (RAG)는 자연어로 지식 기반 데이터베이스에 질문이나 사실적인 정보를 사용하기를 원하는 다양한 usecase에 활용가능한 패턴입니다.\n","\n","이 예제는 RAG의 가장 단순한 형태로서 세 가지 단계로 구성되어 있습니다. \n","\n","- 문답으로 된 엑셀데이터를 문답으로 나누고 embedding하여 지식 기반 데이터베이스 구축\n","- 지식 기반 데이터베이스로부터 사용자 질문과 가장 유사한 답을 추출\n","- 문답의 내용을 토큰화\n","\n","## 내용\n","\n","이 노트북은 다음과 같은 단계로 구성되어 있습니다ㅏ.\n","\n","- [환경설정](#setup)\n","- [chroma 데이터베이스 컬렉션 생성](#create_collection)\n","- [Excel 파일 내용 읽고 출력](#read_excel)\n","- [Excel 파일을 임베딩하여 데이터베이스 구축](#build_base)\n","- [사용자 질문에 대한 답변 생성](#predict)"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"setup\"></a>\n","## 환경 설정\n","\n","이 노트북에 있는 샘플 코드를 실행하기 전에 다음 작업을 완료해야 합니다.\n","\n","-  필요한 패키지를 설치해야 한다\n","\n","    *chromadb: chromadb 데이터베이스에 데이터 삽입, 조회, 업데이트 및 삭제\n","\n","    *pandas: 데이터 프레임 생성, 데이터 분석 및 시각화\n","\n","    *sentence_transformer: 문장 임베딩 생성 및 문장 유사도 계산\n","\n","    *xlrds: Excel 파일에서 데이터 읽기 및 처리\n","\n","    *tqdm: 반복 작업 진행률 표시"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip install \"chromadb==0.5.3\"\n","!pip install \"xlrd==2.0.1\"\n","!pip install \"pandas==2.1.4\"\n","!pip install \"sentence-transformers==3.0.1\"\n","!pip install \"tqdm==4.66.4\"\n","!pip install \"torch==2.3.1\""]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"create_collection\"></a>\n","## ChromaDB에 새로운 컬렉션 생성"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import chromadb\n","client = chromadb.PersistentClient()\n","\n","try: \n","    if client.get_collection(name=\"answers\") is not None:\n","        client.delete_collection(name=\"answers\")\n","except:\n","   pass\n","\n","answers = client.create_collection(\n","        name=\"answers\"\n",")"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"read_excel\"></a>\n","## pandas 라이브러리를 사용하여 엑셀 파일을 읽고 출력"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import io\n","import os\n","\n","filename = os.path.join(os.getcwd(), 'data', 'ChatbotData.xls')\n","df = pd.read_excel(filename)\n","print(df.head())"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"build_base\"></a>\n","## Excel 파일을 임베딩하여 데이터베이스 구축\n","\n","pandas DataFrame에서 데이터를 읽어 문장 임베딩을 생성하고 이를 chunk 단위로 처리하여 answers라는 객체에 추가"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import tqdm\n","from sentence_transformers import SentenceTransformer\n","model = SentenceTransformer('sentence-transformers/xlm-r-100langs-bert-base-nli-stsb-mean-tokens')\n","\n","ids = []\n","metadatas = []\n","embeddings = []\n","\n","for row in tqdm.tqdm(df.iterrows()):\n","    index = row[0]\n","    query = row[1].Q\n","    answer = row[1].A\n","    \n","    metadata = {\n","        \"query\": query,\n","        \"answer\": answer\n","    }\n","    \n","    embedding = model.encode(query, normalize_embeddings=True)\n","    \n","    ids.append(str(index))\n","    metadatas.append(metadata)\n","    embeddings.append(embedding)\n","    \n","chunk_size = 256  # 한 번에 처리할 chunk 크기 설정\n","total_chunks = len(ids)\n","\n","embeddings = [ e.tolist() for e in tqdm.tqdm(embeddings)]\n","\n","for chunk_idx in tqdm.tqdm(range(total_chunks)):\n","    \n","    # chunk 단위로 데이터 자르기\n","    chunk_embeddings = embeddings[chunk_idx]\n","    chunk_ids = ids[chunk_idx]\n","    chunk_metadatas = metadatas[chunk_idx]\n","    \n","    # chunk를 answers에 추가\n","    answers.add(embeddings=chunk_embeddings, ids=chunk_ids, metadatas=chunk_metadatas)"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"predict\"></a>\n","## 사용자 질문에 대한 답변 생성"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["embeddings = model.encode(\"어제 여자친구랑 헤어졌다\", normalize_embeddings=True)\n","result = answers.query(\n","    query_embeddings=embeddings.tolist(),\n","    n_results=1\n",")\n","print(result)"]},{"cell_type":"markdown","metadata":{},"source":["Hugging Face의 transformers 라이브러리를 사용하여 텍스트를 토큰화"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from transformers import AutoTokenizer\n","# 사전 학습된 모델 이름\n","MODEL = 'sentence-transformers/xlm-r-100langs-bert-base-nli-stsb-mean-tokens'\n","tokenizer = AutoTokenizer.from_pretrained(MODEL)\n","result = tokenizer(df.loc[3, 'Q'], add_special_tokens = True, truncation = True, padding = \"max_length\", return_attention_mask = True, return_tensors = \"pt\")\n","print(result)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["tokens = tokenizer.convert_ids_to_tokens(result.input_ids[0])\n","print(tokens)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(tokenizer.convert_tokens_to_string(tokens))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(len(embeddings))\n","print(embeddings)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.10","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":1}
