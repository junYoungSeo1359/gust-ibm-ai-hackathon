{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 노트북 내용\n",
    "\n",
    "이 노트북은 watsonx.ai를 사용한 RAG (Retrieval Augmented Generation)을 시연하기 위한 것입니다. 여기에는 data retrieval, 지식 기본 정보에서 유사도검색 및 모델이 생성한 결과를 확인하는 내용이 포함되어 있습니다.\n",
    "이를 잘 이해하기 위해서는 Python에 대한 기본 지식이 필요하며 모든 코드는 Python 3.10 으로 작성되어 있습니다.\n",
    "\n",
    "### RAG (Retrieval Augmented Generation) \n",
    "Retrieval Augmented Generation (RAG)는 자연어로 지식 기반 데이터베이스에 질문이나 사실적인 정보를 사용하기를 원하는 다양한 usecase에 활용가능한 패턴입니다.\n",
    "\n",
    "이 예제는 RAG의 가장 단순한 형태로서 세 가지 단계로 구성되어 있습니다. \n",
    "\n",
    "- 텍스트 데이타를 passage로 나누고 embedding하여 지식 기반 데이터베이스 구축\n",
    "- 지식 기반 데이터베이스로부터 사용자 질문과 가장 유사한 passage들 추출\n",
    "- 추출된 passage들을 large language model에 입력하여 사용자 질의에 대한 최종 답변 생성.\n",
    "\n",
    "## 내용\n",
    "\n",
    "이 노트북은 다음과 같은 단계로 구성되어 있습니다ㅏ.\n",
    "\n",
    "- [환경설정](#setup)\n",
    "- [지식기반 데이터베이스 구축](#build_base)\n",
    "- [watsonx의 foundation model 접근 설정](#models)\n",
    "- [사용자 질문에 대한 답변 생성](#predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"setup\"></a>\n",
    "## 환경 설정\n",
    "\n",
    "이노트북에 있는 샘플 코드를 실행하기 전에 다음 작업을 완료해야 합니다.\n",
    "\n",
    "- 필요한 python package는 conda environment 혹은 python virtual environment에 python 3.10.12 기반의 독립적인 환경을 만든 후 pip install -r requirements_cp4d.txt를 사용해서 설치.\n",
    "- Cloud Pak for Data 관리자에게 이 시스템에 접근할 수 있는 권한 정보를 획득하세요.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"langchain-community\"\n",
    "!pip install \"langchain\"\n",
    "!pip install \"sentence-transformers\"\n",
    "!pip install \"chromadb\"\n",
    "!pip install \"pydantic\"\n",
    "!pip install -U \"langchain-huggingface\"\n",
    "!pip install \"ibm-watson-machine-learning==1.0.353\"\n",
    "!pip install \"ibm_watsonx_ai==0.2.3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "from ibm_watson_machine_learning.foundation_models.utils.enums import ModelTypes\n",
    "from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams\n",
    "from ibm_watson_machine_learning.foundation_models.utils.enums import DecodingMethods\n",
    "from langchain_ibm import WatsonxLLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Watson Machine Learning에 연결 정보 확인\n",
    "\n",
    "Cloud Pak for Data에서 제공하는 Watson Machine Learning 서비스에 접근하기 위한 인증 정보를 입력한다.\n",
    "여기에는 `url`, `username` 그리고 `api_key`가 포함된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "wml_credentials = {\n",
    "    \"username\": 'jihunkim',\n",
    "    \"apikey\": os.getenv(\"API_KEY\", None),\n",
    "    \"url\": 'https://cpd-watsonx.apps.elskr.zanity.net',\n",
    "    \"instance_id\": 'openshift',\n",
    "    \"version\": '4.8'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### project id 확인\n",
    "Foundation model에 접근하기 위한 Cloud Pak for Data의 project id를 확인 한다.</br>\n",
    "이 노트북이 Foundation model을 제공하는 Cloud Pak for Data이 Project 내에서 실행되는 경우 자동으로 환경 변수에서 가져올 수 있으나 Cloud Pak for Data 외부 환경에서 실행되는 경우는 연관된 project id를 확인한 후에 입력해 줘야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    project_id = os.environ[\"PROJECT_ID\"]\n",
    "    run_in_cp4d = True\n",
    "except KeyError:\n",
    "    run_in_cp4d = False\n",
    "    project_id = \"Your Project ID\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"build_base\"></a>\n",
    "## 기본 지식 정보(knowledge base) 구축\n",
    "\n",
    "The current state-of-the-art in RAG is to create dense vector representations of the knowledge base in order to calculate the semantic similarity to a given user query.\n",
    "최신 기술인 RAG는 사용자 질의에 대한 sematic similarity를 계산하기 위해 기본 지식 정보에 대한 밀집 벡터 표현 (dense vector represenations)를 생성한다.\n",
    "이 기본 예제에서는 \"영화 분노의 도로-퓨리오사 사가\"의 줄거리를 가져와서 chunk로 나누고 embedding 한 후에 Chroma db에 저장하는 것으로 기본 지식 정보를 구축한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document data 로딩\n",
    "\n",
    "샘플 코드에서 사용할 데이타 파일은 단순 텍스트 파일이며 git clone으로 생성된 local repository에서 이 노트북이 존재하는 위치의 아래의 data 폴더에 저장되어있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_in_cp4d:\n",
    "\n",
    "    from ibm_watson_studio_lib import access_project_or_space\n",
    "    wslib = access_project_or_space()\n",
    "\n",
    "    # load data of type \"text/plain\" into a file like object\n",
    "    # raw_data_0 = wslib.load_data('매드맥스-퓨리오사-사가.txt')\n",
    "    wslib.download_file('퓨리오사-줄거리.txt')\n",
    "    filename = '퓨리오사-줄거리.txt'\n",
    "else:\n",
    "    filename = os.path.join(os.getcwd(), 'data', '퓨리오사-줄거리.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader(filename, encoding='UTF8')\n",
    "documents = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '/Users/jihun.kim/Documents/src/p-tect-genai-enablement/08-what-is-rag/data/퓨리오사-줄거리.txt'}, page_content='매드 맥스: 분노의 도로에서 쓰였던 배경 설명 대사들이 나오고 타이틀이 뜬 다음, 지구에서 오스트레일리아 대륙의 황무지 안에 있는 푸른 구역을 보여주는 장면이 나온다.\\n퓨리오사는 동생 발키리와 함께 마을 구역에서 떨어진 장소에서 복숭아를 따먹던 중, 풍요의 땅을 발견하고 사냥을 마친 뒤 떠나려는 바이커 무리를 발견한다. 이들이 떠나면 풍요의 땅의 위치가 외부 세력에 발각 될 것을 우려한 퓨리오사는 동생인 발키리에게 조용히 있으라고 당부한 뒤 홀로 바이커 무리에 접근한다. 이야기를 나누는 바이커들 몰래 오토바이 한대의 연료 호스를 끊어내는 것에 성공했지만, 뒤에서 접근한 바이커에게 발각당하고 만다. 위기 상황에서 부발리니인 어머니, 메리 조 바사를 부르는 피리를 불었지만 결국 바이커들에게 제압당해 끌려가고 만다.[2]'),\n",
       " Document(metadata={'source': '/Users/jihun.kim/Documents/src/p-tect-genai-enablement/08-what-is-rag/data/퓨리오사-줄거리.txt'}, page_content='피리소리를 듣고 찾아온 바사가 다급하게 바이커 무리를 쫒아 대부분의 바이커를 죽이는 것에 성공하지만 두 명의 바이커는 빠져나가고 만다. 풍요의 땅이 존재한다는 증거로서 디멘투스에게 퓨리오사를 직접 진상하고 총애를 받겠다는 늙은 바이커[3]의 계획을 확인한 퓨리오사. 안장에 엎어져 실려가는 와중에도 이로 연료 호스를 물어뜯어 시간을 지연시켜 보았지만 결국 추격해온 바사가 마지막 바이커를 죽이지 못했고[4] 그대로 퓨리오사는 바이커 무리 한복판에 던져진다.'),\n",
       " Document(metadata={'source': '/Users/jihun.kim/Documents/src/p-tect-genai-enablement/08-what-is-rag/data/퓨리오사-줄거리.txt'}, page_content='애꾸눈 바이커인 리즈데일 펠에 의해 디멘투스와 간부 일당 앞에 끌려온 퓨리오사를 보며 생체 기술자는 오염되지 않고 건강하며 잘 먹은 상태임을 확인 시켜준다. 리즈데일 펠은 이 꼬마가 살던 풍요의 땅이라는 곳이 있다는 사실을 디멘투스에게 전하고, 디멘투스는 퓨리오사를 달래는 척 집으로 돌려보내 줄테니 방향을 알려달라고 설득한다.[5] 끝까지 입을 열지 않는 퓨리오사를 보며 디멘투스는 퓨리오사를 깨끗한 물로 씻기고 잘 보살피라는 명령을 내린다.\\n그날 밤, 죽인 바이커의 장구류로 위장한 바사가 퓨리오사를 구하기 위해 찾아온다. 어렵지 않게 경비를 서던 바이커 둘을 죽인 바사는 텐트 안에서 퓨리오사의 몸을 씻기던 여성 바이커도 죽이기 위해 총을 겨누지만, 자신에게도 아이가 있다며 자비를 구걸하는 여성 바이커를 차마 죽이지 못하고 퓨리오사만 챙겨 달아난다.[6]')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0:3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### embedding function 생성\n",
    "\n",
    "여기서는 huggingface에서 제공하는 기본 embedding 함수를 사용한다.\n",
    "다른 embedding 함수를 사용할 수도 있으나 이 경우 embedding 함수와 사용하고자 하는 vector db (여기서는 Chroma)의 embedding size가 일치해야 한다.\n",
    "참고로 Chroma db의 embedding size는 768 이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector DB (Chroma db) 생성\n",
    "\n",
    "chunk로 나누어진 데이터와 embeddng 모델을 사용하여 Chroma db를 생성한다. 이 함수가 실행될 때 각 chunk들이 embedding되고 vector화된 데이터가 원본 텍스트와 함께 db내에 저장된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = Chroma.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"models\"></a>\n",
    "## watsonx의 Foundation model 접근 설정\n",
    "\n",
    "IBM watsonx의 foundation model들은 <a href=\"https://python.langchain.com/v0.2/docs/integrations/providers/ibm/#watsonxllm\" target=\"_blank\" rel=\"noopener no referrer\">langchain에 의해 지원되는 LLM들의 목록</a>에 속한다.\n",
    "여기서는 한글이 잘 동작한다고 평가되는 <a href=\"https://huggingface.co/mncai/llama2-13b-dpo-v7\">mncai/llama2-13b-dpo-v7</a>를 사용한다.\n",
    "\n",
    "WatsonxLLM class는 watsonx foundation model과 langchain 간의 interface를 제공해주는 class이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model 'mncai/llama2-13b-dpo-v7' is not supported for this environment. Supported models: []\n"
     ]
    },
    {
     "ename": "WMLClientError",
     "evalue": "Model 'mncai/llama2-13b-dpo-v7' is not supported for this environment. Supported models: []",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWMLClientError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m model_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmncai/llama2-13b-dpo-v7\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      2\u001b[0m parameters \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m     GenParams\u001b[38;5;241m.\u001b[39mDECODING_METHOD: DecodingMethods\u001b[38;5;241m.\u001b[39mGREEDY\u001b[38;5;241m.\u001b[39mvalue,\n\u001b[1;32m      4\u001b[0m     GenParams\u001b[38;5;241m.\u001b[39mMIN_NEW_TOKENS: \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      5\u001b[0m     GenParams\u001b[38;5;241m.\u001b[39mMAX_NEW_TOKENS: \u001b[38;5;241m500\u001b[39m,\n\u001b[1;32m      6\u001b[0m     GenParams\u001b[38;5;241m.\u001b[39mSTOP_SEQUENCES: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<|endoftext|>\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      7\u001b[0m }\n\u001b[0;32m----> 8\u001b[0m watsonx_llama2_korean \u001b[38;5;241m=\u001b[39m \u001b[43mWatsonxLLM\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwml_credentials\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43musername\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwml_credentials\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43musername\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapikey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwml_credentials\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mapikey\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43minstance_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwml_credentials\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minstance_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/genai-edu/lib/python3.10/site-packages/pydantic/v1/main.py:339\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03mCreate a new model by parsing and validating input data from keyword arguments.\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03mRaises ValidationError if the input data cannot be parsed to form a valid model.\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;66;03m# Uses something other than `self` the first arg to allow \"self\" as a settable attribute\u001b[39;00m\n\u001b[0;32m--> 339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m__pydantic_self__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n",
      "File \u001b[0;32m~/miniforge3/envs/genai-edu/lib/python3.10/site-packages/pydantic/v1/main.py:1100\u001b[0m, in \u001b[0;36mvalidate_model\u001b[0;34m(model, input_data, cls)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1100\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mvalidator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcls_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mAssertionError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m   1102\u001b[0m     errors\u001b[38;5;241m.\u001b[39mappend(ErrorWrapper(exc, loc\u001b[38;5;241m=\u001b[39mROOT_KEY))\n",
      "File \u001b[0;32m~/miniforge3/envs/genai-edu/lib/python3.10/site-packages/langchain_ibm/llms.py:214\u001b[0m, in \u001b[0;36mWatsonxLLM.validate_environment\u001b[0;34m(cls, values)\u001b[0m\n\u001b[1;32m    188\u001b[0m             values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstance_id\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m convert_to_secret_str(\n\u001b[1;32m    189\u001b[0m                 get_from_dict_or_env(\n\u001b[1;32m    190\u001b[0m                     values, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstance_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWATSONX_INSTANCE_ID\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    191\u001b[0m                 )\n\u001b[1;32m    192\u001b[0m             )\n\u001b[1;32m    193\u001b[0m     credentials \u001b[38;5;241m=\u001b[39m Credentials(\n\u001b[1;32m    194\u001b[0m         url\u001b[38;5;241m=\u001b[39mvalues[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget_secret_value() \u001b[38;5;28;01mif\u001b[39;00m values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    195\u001b[0m         api_key\u001b[38;5;241m=\u001b[39mvalues[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapikey\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget_secret_value()\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    211\u001b[0m         verify\u001b[38;5;241m=\u001b[39mvalues[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverify\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    212\u001b[0m     )\n\u001b[0;32m--> 214\u001b[0m     watsonx_model \u001b[38;5;241m=\u001b[39m \u001b[43mModelInference\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeployment_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdeployment_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparams\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproject_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mproject_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspace_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspace_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m     values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwatsonx_model\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m watsonx_model\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m values\n",
      "File \u001b[0;32m~/miniforge3/envs/genai-edu/lib/python3.10/site-packages/ibm_watsonx_ai/foundation_models/inference/model_inference.py:171\u001b[0m, in \u001b[0;36mModelInference.__init__\u001b[0;34m(self, model_id, deployment_id, params, credentials, project_id, space_id, verify, api_client, validate)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference: BaseModelInference\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_id:\n\u001b[0;32m--> 171\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference \u001b[38;5;241m=\u001b[39m \u001b[43mFMModelInference\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapi_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeployment_id \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeployment_id)\n",
      "File \u001b[0;32m~/miniforge3/envs/genai-edu/lib/python3.10/site-packages/ibm_watsonx_ai/foundation_models/inference/fm_model_inference.py:63\u001b[0m, in \u001b[0;36mFMModelInference.__init__\u001b[0;34m(self, model_id, api_client, params, validate)\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tech_preview:\n\u001b[0;32m---> 63\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m WMLClientError(\n\u001b[1;32m     64\u001b[0m                 error_msg\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not supported for this environment. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     65\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSupported models: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msupported_models\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     66\u001b[0m             )\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# check if model is in constricted mode\u001b[39;00m\n\u001b[1;32m     69\u001b[0m _check_model_state(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_id, tech_preview\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tech_preview)\n",
      "\u001b[0;31mWMLClientError\u001b[0m: Model 'mncai/llama2-13b-dpo-v7' is not supported for this environment. Supported models: []"
     ]
    }
   ],
   "source": [
    "model_id = 'mncai/llama2-13b-dpo-v7'\n",
    "parameters = {\n",
    "    GenParams.DECODING_METHOD: DecodingMethods.GREEDY.value,\n",
    "    GenParams.MIN_NEW_TOKENS: 1,\n",
    "    GenParams.MAX_NEW_TOKENS: 500,\n",
    "    GenParams.STOP_SEQUENCES: [\"<|endoftext|>\"]\n",
    "}\n",
    "watsonx_llama2_korean = WatsonxLLM(\n",
    "    model_id=model_id,\n",
    "    url=wml_credentials.get(\"url\"),\n",
    "    username=wml_credentials.get(\"username\"),\n",
    "    apikey=wml_credentials.get(\"apikey\"),\n",
    "    instance_id=wml_credentials.get(\"instance_id\"),\n",
    "    project_id=project_id,\n",
    "    params=parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사용자 질의 검색 테스트\n",
    "\n",
    "앞서 구축한 지식 기반 정보로부터 사용자의 질의와 가장 유사한 정보를 검색해서 출력해 본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever(search_kwargs={'k': 2})\n",
    "resutls = retriever.get_relevant_documents(\"퓨리오사가 한 쪽 팔을 잃게되는 경위가 뭔가요?\")\n",
    "resutls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"predict\"></a>\n",
    "## RAG를 사용하여 사용자 질문에 대한 답변을 생성한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "langchain의 `RetrievalQA` (question answering chain) 를 사용하여 RAG 작업을 자동으로 수행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(llm=watsonx_llama2_korean, chain_type=\"stuff\", retriever=retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa.invoke(\"퓨리오사가 한 쪽 팔을 잃게되는 경위가 뭔가요?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"등장인물 중 잭은 어떤 역할인가요?\"\n",
    "qa.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa.invoke(\"퓨리오사는 어떻게 어머니의 복수를 하나요?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ibm-edu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
