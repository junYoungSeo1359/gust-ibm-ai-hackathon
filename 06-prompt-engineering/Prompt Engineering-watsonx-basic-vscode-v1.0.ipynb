{"cells":[{"cell_type":"markdown","metadata":{},"source":["![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n","# Prompt Lab on Notebook v1.0\n","\n","이 노트북에는 프롬프트 추론을 시연하는 단계와 코드가 포함되어 있습니다.  \n","프롬프트 추론을 시연하는 단계와 코드가 포함되어 있습니다. 여기에는 API 키를 사용하여 인증하는 Python API 명령  \n","을 사용한 인증과 WML API를 사용한 프롬프트 추론에 대해 소개합니다.  \n","**Note:** 프롬프트 랩을 사용하여 생성된 노트북 코드는 성공적으로 실행됩니다.\n","코드가 수정되거나 순서가 바뀌면 성공적으로 실행된다는 보장은 없습니다.  \n","자세한 내용은 다음을 참조하세요: <a href=\"/docs/content/wsj/analyze-data/fm-prompt-save.html?context=wx\" target=\"_blank\">프롬프트 랩에서 작업을 노트북으로 저장하기.</a>\n","\n","Python에 어느 정도 익숙하면 도움이 됩니다. 이 노트북은 Python 3.10을 사용합니다.\n","\n","## Notebook goals\n","이 노트북의 학습 목표는 다음과 같습니다:\n","\n","* IBM Cloud 개인 API 키에서 자격 증명을 얻기 위한 Python 함수 정의하기\n","* 모델 객체의 매개변수 정의하기\n","* 모델 개체를 사용하여 정의된 모델 ID, 매개변수 및 프롬프트 입력을 사용하여 응답 생성하기\n","\n","## 소개\n","watson studio에서 실습하는 것을 vscode에서 실습하기 위해 lab입니다.  \n"]},{"cell_type":"markdown","metadata":{},"source":["#### 실습환경 구성"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip install ibm-watson-machine-learning python-dotenv"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from dotenv  import load_dotenv\n","from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams\n","from ibm_watson_machine_learning.foundation_models.model import Model \n","\n","import os \n","\n","load_dotenv()\n","\n","credentials = {\n","\t\t\"url\" : \"https://us-south.ml.cloud.ibm.com\",\n","\t\t\"apikey\" : os.getenv(\"API_KEY\", None)\n","\t}\n","\n","project_id = os.getenv(\"PROJECT_ID\", None)\n","\n","def get_completion(prompt):\n","    # Instantiate parameters for text generation\n","    params = {\n","        GenParams.DECODING_METHOD: 'greedy',\n","        GenParams.MIN_NEW_TOKENS: 1,\n","        GenParams.MAX_NEW_TOKENS: 400,\n","        GenParams.TEMPERATURE: 0.2,\n","        GenParams.RANDOM_SEED: 42,\n","        GenParams.REPETITION_PENALTY: 1.0,\n","        GenParams.STOP_SEQUENCES : [\"\\n\\n\"]\n","    }\n","    \n","    # Instantiate a model proxy object to send your requests\n","    model = Model(\n","        model_id='meta-llama/llama-3-70b-instruct',\n","        params=params,\n","        credentials=credentials, # type: ignore\n","        project_id=project_id)\n","\n","    response = model.generate_text(prompt = prompt)\n","\n","    return response"]},{"cell_type":"markdown","metadata":{},"source":["#### 실습 예제"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["text_1 = \"\"\"\n","```차 한잔 끓이는 방법은 간단해요! 먼저 물을 좀 끓여야 합니다. \n","그 동안 컵을 들고 그 안에 티백을 넣으세요. \n","물이 충분히 뜨거워지면 티백 위에 부어주세요. \n","차가 가파르게 될 수 있도록 잠시 그대로 두십시오. \n","몇 분 후 티백을 꺼냅니다. \n","원하시면 설탕이나 우유를 조금 첨가해 드셔도 좋습니다. \n","그리고 그게 다입니다.! 맛있는 차 한잔을 즐기실 수 있습니다.```\n","\"\"\"\n","prompt = f\"\"\"\n","\n","{text_1}\n","\n","삼중따옴표로 구분된 텍스트가 제공됩니다. 일련의 지침이 포함된 경우 해당 지침을 다음 형식으로 다시 작성하세요.\n","단계 1 - ...\n","단계 2 - …\n","…\n","Step N - …\n","\n","결과 : \n","\"\"\"\n","\n","response = get_completion(prompt)\n","print(response)"]},{"cell_type":"markdown","metadata":{},"source":["### 원칙 1: 명확하고 구체적인 지침을 작성하세요.\n","\n","모델이 의도와 원하는 결과를 이해할 수 있도록 프롬프트가 명확하고 간결해야 합니다. 다양한 해석으로 이어질 수 있는 모호한 언어나 표현을 피하세요. 이는 다음과 같은 전략을 통해 달성할 수 있습니다.\n","\n","#### 전략 1: 구분 기호를 사용하여 입력의 개별 부분을 명확하게 나타냅니다.\n","\n","구분 기호는 잘못된 사용자 입력으로 인한 잠재적인 간섭을 방지하는 데 도움이 됩니다. 구분 기호의 예는 다음과 같습니다.\n","\n","- Triple quotes: `\"\"\"`\n","- Triple backticks: ```` ``` ````\n","- Triple dashes: `---`\n","- Angle brackets: `<>`\n","- XML tags: `<tag>`\n","\n","Example:\n","\n","```python\n","text = \"\"\"\n","```가능한 한 명확하고 구체적인 지침을 제공하여 모델이 수행하기를 원하는 작업을 표현해야 합니다. \n","이렇게 하면 모델이 원하는 출력으로 안내되고 관련이 없거나 잘못된 응답을 받을 가능성이 줄어듭니다. \n","명확한 프롬프트 작성과 짧은 프롬프트 작성을 혼동하지 마십시오. \n","대부분의 경우 프롬프트가 길수록 모델에 대한 명확성과 맥락이 더 높아져 더 자세하고 관련성이 높은 결과를 얻을 수 있습니다.```\n","\"\"\"\n","prompt = f\"\"\"\n","\n","{text}\n","\n","삼중따옴표로 구분된 텍스트를 한 문장으로 요약합니다.\n","\n","결과 : \n","\"\"\"\n","response = get_completion(prompt)\n","print(response)\n","```\n","\n","#### 전략 2: 구조화된 출력 요청\n","\n","이 접근 방식은 Python 프로그램에서 읽고 사전 형식으로 변환할 수 있는 JSON 출력과 같은 모델 출력을 프로그램에 직접 사용할 수 있도록 하는 데 도움이 됩니다.\n","\n","Example:\n","\n","```python\n","prompt = \"\"\"\n","저자 및 장르와 함께 구성된 책 제목 3개 목록을 생성합니다. book_id, 제목, 저자, 장르 키를 사용하여 JSON 형식으로 제공하세요.\n","\"\"\"\n","response = get_completion(prompt)\n","print(response)\n","```\n","\n","<mark> Result:\n","```json\n","[\n","  {\n","    \"book_id\": 1,\n","    \"title\": \"The Lost City of Zorath\",\n","    \"author\": \"Aria Blackwood\",\n","    \"genre\": \"Fantasy\"\n","  },\n","  {\n","    \"book_id\": 2,\n","    \"title\": \"The Last Survivors\",\n","    \"author\": \"Ethan Stone\",\n","    \"genre\": \"Science Fiction\"\n","  },\n","]\n","\n","```\n","\n","#### 전략 3: 원하는 조건을 주어, 충족 여부를 확인\n","\n","작업 완료에 충족되어야 하는 전제 조건이 있는 경우 모델에 이러한 조건을 먼저 확인하고 충족되지 않으면 시도를 중지하도록 지시해야 합니다.\n","\n","Example:\n","\n","```python\n","text_1 = \"\"\"\n","```차 한잔 끓이는 방법은 간단해요! 먼저 물을 좀 끓여야 합니다. \n","그 동안 컵을 들고 그 안에 티백을 넣으세요. \n","물이 충분히 뜨거워지면 티백 위에 부어주세요. \n","차가 가파르게 될 수 있도록 잠시 그대로 두십시오. \n","몇 분 후 티백을 꺼냅니다. \n","원하시면 설탕이나 우유를 조금 첨가해 드셔도 좋습니다. \n","그리고 그게 다입니다.! 맛있는 차 한잔을 즐기실 수 있습니다.```\n","\"\"\"\n","prompt = f\"\"\"\n","\n","{text_1}\n","\n","삼중따옴표로 구분된 텍스트가 제공됩니다. 일련의 지침이 포함된 경우 해당 지침을 다음 형식으로 다시 작성하세요.\n","단계 1 - ...\n","단계 2 - …\n","…\n","Step N - …\n","\n","결과 : \n","\"\"\"\n","response = get_completion(prompt)\n","print(response)\n","```\n","\n","<mark> Output:\n","```\n","1 단계 - 물을 좀 끓여야 합니다.\n","2 단계 - 컵을 들고 그 안에 티백을 넣으세요.\n","3 단계 - 물이 충분히 뜨거워지면 티백 위에 부어주세요.\n","4 단계 - 차가 우러날 수 있도록 잠시 놓아두세요.\n","5 단계 - 몇 분 후 티백을 꺼내세요..\n","6 단계 - 원하시면 설탕이나 우유를 조금 첨가해 드셔도 좋습니다.\n","```\n","\n","#### 전략 4: “N-shot” Prompting\n","\n","모델에 하나 이상의 샘플 프롬프트를 제공하면 예상되는 출력을 명확히 하는 데 도움이 됩니다.\n","Providing the model with one or more sample prompts helps clarify the expected output.\n","Zero-shot 및 Few-shot 프롬프트를 포함한 N-shot 프롬프트는 예측을 위해 모델에 제공되는 \"훈련\" 사례 또는 단서의 수를 나타냅니다.\n","\n","<table width=\"80%\">\n","  <tr>\n","    <td width=\"20%\" style=\"text-align: center\">유형</td>\n","    <td width=\"40%\" style=\"text-align: center\">설명</td>\n","    <td width=\"40%\" style=\"text-align: center\"> 예</td>\n","  </tr>\n","  <tr>\n","    <td style=\"text-align: left;\">Zero-shot 프롬프팅</td>\n","    <td style=\"text-align: left;\">모델은 추가 교육 없이 예측을 수행합니다. 이는 분류 또는 텍스트 변환과 같은 일반적인 간단한 문제에 효과적입니다..</td>\n","    <td style=\"text-align: left;\">분류 (예. 감정분석, 스팸 분류 => \"이 메일은 스펨인가요? 아닌가요? ==> <i>이메일 콘텐츠 붙여넣기</i> \"), 텍스트 변환(예: 번역, 요약, 확장) 및 LLM이 주로 교육받은 간단한 텍스트 생성</td>\n","  </tr>\n","  <tr>\n","    <td style=\"text-align: left;\">Few-shot 프롬프팅</td>\n","    <td style=\"text-align: left;\">이러한 작은 예를 기반으로 출력을 조정하기 위해 소량의 데이터(일반적으로 2~5개)를 사용합니다. 이러한 예는 보다 상황에 맞는 문제에 대해 더 나은 성능을 발휘하도록 모델을 조정하기 위한 것입니다.</td>\n","    <td style=\"text-align: left;\">\"다음 영어 문장을 프랑스어로 번역하세요: '안녕하세요, 잘 지내세요?' '나는 괜찮아요, 고마워요.'\" </td>\n","  </tr>    \n","     \n","</table>    \n","\n","### 원칙 2: 모델에게 \"생각\"할 시간을 주십시오\n","\n","이 원칙은 사고 사슬의 아이디어를 활용하여 복잡한 작업을 N개의 순차적 하위 작업으로 나누어 모델이 단계별로 사고하고 보다 정확한 출력을 생성할 수 있도록 합니다.\n","\n","#### 전략 1: 작업을 완료하는 데 필요한 단계 지정\n","\n","다음은 텍스트를 요약하고, 프랑스어로 번역하고, 프랑스어 요약에 이름을 나열하고, 마지막으로 데이터를 JSON 형식으로 출력하는 것과 관련된 예입니다. 필요한 단계를 제공함으로써 모델은 이전 단계의 결과를 참조하고 출력의 정확성을 향상시킬 수 있습니다.\n","\n","\n","#### 전략 2: 성급하게 결론을 내리기 전에 모델에 자체 솔루션을 마련하도록 지시\n","\n","작업이 너무 복잡하거나 설명이 너무 적으면 모델은 추측을 통해서만 결론을 도출할 수 있습니다. 따라서 이 경우 문제에 대해 생각하는 데 더 오랜 시간이 걸리도록 모델에 지시할 수 있습니다."]},{"cell_type":"markdown","metadata":{},"source":["## Prompting on  IBM Watsonx\n","ibm watsonx platform에서 prompting을 하기위해 사전에 설치해야하는 파이썬 패키지를 다음과 같이 설치합니다. "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip install ibm-watson-machine-learning python-dotenv"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from dotenv import load_dotenv\n","import os  \n","\n","load_dotenv()\n","\n","credentials = {\n","\t\t\"url\" : \"https://us-south.ml.cloud.ibm.com\",\n","\t\t\"apikey\" : os.getenv(\"API_KEY\", None)\n","\t}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["project_id = os.getenv(\"PROJECT_ID\", None)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from ibm_watson_machine_learning.foundation_models import Model\n","from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams\n","\n","def send_to_watsonxai(prompts,\n","                    model_name=\"meta-llama/llama-2-70b-chat\",\n","                    decoding_method=\"greedy\",\n","                    max_new_tokens=100,\n","                    min_new_tokens=30,\n","                    temperature=1.0,\n","                    repetition_penalty=1.0,\n","                    stop_sequence=['\\n\\n']\n","                    ):\n","    '''\n","   프롬프트 및 매개 변수를 watsonx.ai로 보내기 위한 function\n","    \n","    Args:  \n","        prompts: 텍스트 프롬프트\n","        decoding_method: \"sample\" or \"greedy\"\n","        max_new_token:int watsonx.ai parameter for max new tokens/response returned\n","        temperature:float watsonx.ai parameter for temperature (range 0>2)\n","        repetition_penalty:float watsonx.ai parameter for repetition penalty (range 1.0 to 2.0)\n","\n","    Returns: None\n","        prints response\n","    '''\n","\n","    assert not any(map(lambda prompt: len(prompt) < 1, prompts)), \"make sure none of the prompts in the inputs prompts are empty\"\n","\n","    # Instantiate parameters for text generation\n","    model_params = {\n","        GenParams.DECODING_METHOD: decoding_method,\n","        GenParams.MIN_NEW_TOKENS: min_new_tokens,\n","        GenParams.MAX_NEW_TOKENS: max_new_tokens,\n","        GenParams.RANDOM_SEED: 42,\n","        GenParams.TEMPERATURE: temperature,\n","        GenParams.REPETITION_PENALTY: repetition_penalty,\n","        GenParams.STOP_SEQUENCES : stop_sequence\n","    }\n","    \n","    # Instantiate a model proxy object to send your requests\n","    model = Model(\n","        model_id=model_name,\n","        params=model_params,\n","        credentials=credentials, # type: ignore\n","        project_id=project_id)\n","\n","    response = model.generate_text(prompt = prompt)\n","\n","    return response   "]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["FLAN_T5_XXL = 'google/flan-t5-xxl'\n","FLAN_UL2 = 'google/flan-ul2'\n","GPT_NEOX = 'eleutherai/gpt-neox-20b'\n","GRANITE_13B_CHAT = 'ibm/granite-13b-chat-v1'\n","GRANITE_13B_INSTRUCT = 'ibm/granite-13b-instruct-v1'\n","LLAMA_2_70B_CHAT = 'meta-llama/llama-2-70b-chat'\n","LLAMA_3_70B_INSTRUCT=\"meta-llama/llama-3-70b-instruct\"\n","MPT_7B_INSTRUCT2 = 'ibm/mpt-7b-instruct2'\n","MT0_XXL = 'bigscience/mt0-xxl'\n","STARCODER = 'bigcode/starcoder'\n","MISTRAL_LARGE = \"mistralai/mistral-large\""]},{"cell_type":"markdown","metadata":{},"source":["#### 원칙1 > 구분 기호를 사용하여 입력의 개별 부분을 명확하게 표시 "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["input = \"\"\"\n","\n","가능한 한 명확하고 구체적인 지침을 제공하여 모델이 수행하기를 원하는 작업을 표현해야 합니다. \n","이렇게 하면 모델이 원하는 출력으로 안내되고 관련이 없거나 잘못된 응답을 받을 가능성이 줄어들고,\n","명확한 프롬프트 작성과 짧은 프롬프트 작성을 혼동하지 마십시오. \n","대부분의 경우 프롬프트가 길수록 모델에 대한 명확성과 맥락이 더 높아져 더 자세하고 관련성이 높은 결과를 얻을 수 있습니다.\n","\n","위 세 개로 구분된 텍스트를 한 문장으로 요약해서 한글로 출력합니다. \n","\"\"\"\n","\n","prompt = f\"\"\"\n","\n","{input}\n","\"\"\"\n","\n","response = send_to_watsonxai(prompts=[prompt], model_name=LLAMA_3_70B_INSTRUCT, decoding_method=\"greedy\", max_new_tokens=400,\n","                              min_new_tokens=1, temperature=0, repetition_penalty=1.0)\n","print(response)"]},{"cell_type":"markdown","metadata":{},"source":["#### 원칙1 > 구조화된 출력형식 요청"]},{"cell_type":"markdown","metadata":{},"source":["#### 실습 1"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["input = \"\"\" \n","입력 : 저자 및 장르와 함께 구성된 책 제목 3개 목록을 생성합니다. \n","book_id, 제목, 저자, 장르 키를 사용하여 JSON 형식으로 출력해줘 \n","\n","출력 : \n","\n","\"\"\"\n","\n","prompt = f\"\"\"\n","\n","{input}\n","\"\"\"\n","\n","response = send_to_watsonxai(prompts=[prompt], model_name=LLAMA_3_70B_INSTRUCT, decoding_method=\"sample\", max_new_tokens=200,\n","                              min_new_tokens=1, temperature=0, repetition_penalty=1.0, stop_sequence=[\"\\n\\n\", \"```\"])\n","print(response)"]},{"cell_type":"markdown","metadata":{},"source":["#### 실습 2 "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["input = '''\n","def generate_sentence(sentence: str) -> str:\n","    \"\"\"\n","    입력된 문장의 감정(긍정 또는 부정)을 예측합니다.\n"," \n","    Parameters:\n","        sentence (str): Input sentence\n","    \n","    Returns:\n","        str: Sentiment of the input ('positive' or 'negative')\n","    \"\"\"\n","    # 다른 곳에 sentiment_is_positive(sentence) 함수가 정의되어 있다고 가정합니다.\n","    if sentiment_is_positive(sentence):\n","        return \"positive\"\n","    else:\n","        return \"negative\"\n","\n","\n","print(generate_sentence(\"매력적인 분위기가 느껴집니다\"))\n","\n","result : \n","'''\n","\n","prompt = f\"\"\"\n","\n","{input}\n","\"\"\"\n","\n","response = send_to_watsonxai(prompts=[prompt], model_name=LLAMA_3_70B_INSTRUCT, decoding_method=\"greedy\", max_new_tokens=400,\n","                              min_new_tokens=1, temperature=0, repetition_penalty=1.0, stop_sequence=[\"\\n\\n\", \"```\"])\n","print(response)"]},{"cell_type":"markdown","metadata":{},"source":["## 원칙1 > 구분 기호를 사용하여 입력의 개별 부분을 명확하게 표시"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["input = \"\"\"\n","\n","다음 텍스트에서 장소의 이름을 추출해 줘.\n","\n","원하는 형식:\n","Place: <comma_separated_list_of_places>\n","입력:  이러한 발전은 연구자들에게 격려가 되지만, \n","많은 것들이 여전히 수수께끼입니다. 리스본에 있는 샴팔리마우드 센터(CCU: Champalimaud Centre for the Unknown)의 신경면역학자인 Henrique Veiga-Fernandes는\n","\"뇌와 주변부에서 보이는 효과 사이에 블랙박스가 있는 경우가 종종 있습니다.\"라고 말합니다. 그리고 다음과 같이 덧붙입니다. \n","\"치료적 맥락에서 이를 사용하고자 할 경우, 그 메커니즘을 실제로 이해할 필요가 있습니다.\"\n","\"\"\"\n","\n","prompt = f\"\"\"\n","\n","{input}\n","\"\"\"\n","\n","response = send_to_watsonxai(prompts=[prompt], model_name=LLAMA_3_70B_INSTRUCT, decoding_method=\"greedy\", max_new_tokens=400,\n","                              min_new_tokens=1, temperature=1, repetition_penalty=1.0, stop_sequence=[\"\\n\\n\", \"```\"])\n","\n","print(response)"]},{"cell_type":"markdown","metadata":{},"source":["#### 원칙1 > 조건이 충족되는지 확인하기 "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["input = \"\"\"\n","```차 한잔 끓이는 방법은 간단해요! 먼저 물을 좀 끓여야 합니다. 그 동안 컵을 들고 그 안에 티백을 넣으세요. \n","물이 충분히 뜨거워지면 티백 위에 부어주세요. 차가 가파르게 될 수 있도록 잠시 그대로 두십시오. \n","몇 분 후 티백을 꺼냅니다. 원하시면 설탕이나 우유를 조금 첨가해 드셔도 좋습니다. \n","그리고 그게 다입니다.! 맛있는 차 한잔을 즐기실 수 있습니다.```\n","\"\"\"\n","\n","prompt = f\"\"\"\n","\n","{input}\n","\n","삼중따옴표로 구분된 텍스트가 제공됩니다. 일련의 지침이 포함된 경우 해당 지침을 다음 형식으로 다시 작성하세요.\n","단계 1 - ...\n","단계 2 - …\n","…\n","단계 N - …\n","\n","결과 : \n","\"\"\"\n","\n","response = send_to_watsonxai(prompts=[prompt], model_name=LLAMA_3_70B_INSTRUCT, decoding_method=\"greedy\", max_new_tokens=200,\n","                              min_new_tokens=1, temperature=1, repetition_penalty=1.0)\n","\n","print(response)"]},{"cell_type":"markdown","metadata":{},"source":["#### 원칙1 > N-shot Prompting "]},{"cell_type":"markdown","metadata":{},"source":["#### 실습1- 프롬프트로 삼행시를 작성해 보세요"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["input = \"\"\"\n","Context : 입력한 값을 한글로 삼행시를 작성.\n","예제 : \n","입력 : 아이유를 삼행시로 만들어줘.\n","출력 : \n","아: 아름다운 \n","이: 이별을 \n","유: 유쾌하게 노래하는 아이유\n","\n","입력 :  IBM을 삼행시로 만들어줘.\n","출력 :\n","\n","\"\"\"\n","\n","prompt = f\"\"\"\n","\n","{input}\n","\"\"\"\n","\n","response = send_to_watsonxai(prompts=[prompt], model_name=LLAMA_3_70B_INSTRUCT, decoding_method=\"greedy\", max_new_tokens=400,\n","                              min_new_tokens=1, temperature=1, repetition_penalty=1.0)\n","\n","print(response)"]},{"cell_type":"markdown","metadata":{},"source":["#### 과제- 프롬프트로 사행시를 작성해 보세요"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["input = \"\"\"\n","Context : 입력한 값을 한글로 삼행시를 작성.\n","\n","입력 : 블랙핑크를 사행시를 만들어줘 \n","출력 : \n","\n","\"\"\"\n","\n","prompt = f\"\"\"\n","\n","{input}\n","\"\"\"\n","\n","response = send_to_watsonxai(prompts=[prompt], model_name=LLAMA_3_70B_INSTRUCT, decoding_method=\"greedy\", max_new_tokens=400,\n","                              min_new_tokens=1, temperature=1, repetition_penalty=1.0)\n","\n","print(response)"]},{"cell_type":"markdown","metadata":{},"source":["#### 실습2 : 2-shot 프롬프트"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["input = '''\n","def generate_sentence(sentence: str) -> str:\n","    \"\"\"\n","    입력된 문장의 감정(긍정 또는 부정)을 예측합니다.\n"," \n","    Parameters:\n","        sentence (str): Input sentence\n","    \n","    Returns:\n","        str: Sentiment of the input ('positive' or 'negative')\n","    \"\"\"\n","    # 다른 곳에 sentiment_is_positive(sentence) 함수가 정의되어 있다고 가정합니다.\n","    if sentiment_is_positive(sentence):\n","        return \"positive\"\n","    else:\n","        return \"negative\"\n","\n","예시 : \n","print(generate_sentence(\"새 제품이 빈번하게 먹통이 되어 환불을 받고 싶다\"))\n","negative\n","\n","print(generate_sentence(\"새 제품을 구매하고, 가성비가 좋아 부모님 것도 구매했어요.\"))\n","positive\n","\n","print(generate_sentence(\"이 제품은 완전히 쓰레기입니다. 하지만 가격이 싸서 구매했어요. 그래도 사용해보고 싶어요. 그리고 좋은 점도 있어요. 그리고 좋은 점이 더 많아요.\"))\n","\n","'''\n","\n","\n","prompt = f\"\"\"\n","\n","{input}\n","\"\"\"\n","\n","response = send_to_watsonxai(prompts=[prompt], model_name=LLAMA_3_70B_INSTRUCT, decoding_method=\"greedy\", max_new_tokens=400,\n","                              min_new_tokens=1, temperature=1, repetition_penalty=1.0)\n","\n","print(response)"]},{"cell_type":"markdown","metadata":{},"source":["#### CoT 프롬프트 "]},{"cell_type":"markdown","metadata":{},"source":["#### 실습 1"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["input = \"\"\"\n","질문: 리사는 테니스공 5개를 가지고 있습니다. \n","    그는 테니스 공 2캔을 더 삽니다. 각 캔에는 테니스 공 3개가 들어 있습니다. \n","    이제 리사는 몇 개의 테니스 공을 가지고 있을까요?\n","답변 : \n","\"\"\"\n","\n","prompt = f\"\"\"\n","\n","{input}\n","\"\"\"\n","\n","response = send_to_watsonxai(prompts=[prompt], model_name=LLAMA_3_70B_INSTRUCT, decoding_method=\"greedy\", max_new_tokens=400,\n","                              min_new_tokens=1, temperature=0.2, repetition_penalty=1.0)\n","\n","print(response)"]},{"cell_type":"markdown","metadata":{},"source":["#### 과제 : 아래 프롬프트를 LLM이 CoT 사고사슬을 하도록 수정하세요."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["input = \"\"\" \n","Q: 조는 평균적으로 분당 25번의 펀치를 던집니다. 시합은 3분씩 5라운드로 진행됩니다. 조는 몇 번의 펀치를 던졌을까요? \n","A: \n","\n","\"\"\"\n","\n","prompt = f\"\"\"\n","\n","{input}\n","\"\"\"\n","\n","response = send_to_watsonxai(prompts=[prompt], model_name=LLAMA_3_70B_INSTRUCT, decoding_method=\"greedy\", max_new_tokens=400,\n","                              min_new_tokens=1, temperature=0.2, repetition_penalty=1.0)\n","\n","print(response)"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":1}
